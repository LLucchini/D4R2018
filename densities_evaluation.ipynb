# ------------------------------------------------------------------------------------------------ #
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib as mpl
%matplotlib inline

dateparse = lambda x: pd.datetime.strptime(x, '%d-%m-%Y %H')

### One file per time
cdr_data_path = 'Dataset 1_201701.txt'
sms_data_path = 'Dataset 1_SMS_201701.txt'
base_station_location_path = 'Base_Station_Location.txt'
overlap_shapefile = 'overlap_file.shp'
groundtruth_data_path = 'RefugeesTurkishPopulationGADM.csv'

### Output file name
output_densities_name = 'densities_province.pkl'
fig_output = ''
# ------------------------------------------------------------------------------------------------ #


# ------------------------------------------------------------------------------------------------ #
### Load CDR data
cdr_data = pd.read_csv(cdr_data_path, encoding = 'utf-8', parse_dates=[0], date_parser=dateparse)
cdr_data = cdr_data[cdr_data.TIMESTAMP.apply(lambda x:x.hour>=20 or x.hour<=7)]
### Load SMS data
sms_data = pd.read_csv(sms_data_path, encoding = 'utf-8', parse_dates=[0], date_parser=dateparse)
sms_data = sms_data[sms_data.TIMESTAMP.apply(lambda x:x.hour>=20 or x.hour<=7)]
### Load base_station data
cell_location = pd.read_csv(base_station_location_path, encoding = 'utf-8', error_bad_lines=False)
### Load VORONOI overlap shapefile
shapefile = gpd.read_file(overlap_shapefile)
### Load GROUND TRUTH
groundtruth = pd.read_csv(groundtruth_data_path, encoding = 'utf-8')
groundtruth = groundtruth[['gadm_province','Refugees','Population']].set_index('gadm_province')
groundtruth = groundtruth.drop(np.nan,axis=0).sort_index()
# ------------------------------------------------------------------------------------------------ #


# ------------------------------------------------------------------------------------------------ #
### Check for tower duplicates and assign the same site id to the tower with the same coordinates
duplicates = cell_location.groupby(['MX_LAT1','MX_LAT2','MX_LAT3','MX_LONG1','MX_LONG2','MX_LONG3']).apply(lambda x:[(x.iloc[i]['BTS_ID'],x.iloc[0]['BTS_ID']) for i in range(len(x))] )
dizionario_duplicates = dict([item for sublist in duplicates.values for item in sublist])

cdr_data['INCOMING_SITE_ID'] = cdr_data['INCOMING_SITE_ID'].map(dizionario_duplicates)
cdr_data['OUTGOING_SITE_ID'] = cdr_data['OUTGOING_SITE_ID'].map(dizionario_duplicates)
sms_data['INCOMING_SITE_ID'] = sms_data['INCOMING_SITE_ID'].map(dizionario_duplicates)
sms_data['OUTGOING_SITE_ID'] = sms_data['OUTGOING_SITE_ID'].map(dizionario_duplicates)
# ------------------------------------------------------------------------------------------------ #


# ------------------------------------------------------------------------------------------------ #
### Build a dataframe "df_sigma_c" that contains the call/sms density for the different province/district (polygons)
# _t stands for turk data and _r for refugee data
# Here we assume that the refugee are not taken into account in the turk population numbers
incoming_calls_t = cdr_data.groupby(['INCOMING_SITE_ID'])['NUMBER_OF_CALLS'].sum()-\
                   cdr_data.groupby(['INCOMING_SITE_ID'])['NUMBER_OF_REFUGEE_CALLS'].sum()
outgoing_calls_t = cdr_data.groupby(['OUTGOING_SITE_ID'])['NUMBER_OF_CALLS'].sum()-\
                   cdr_data.groupby(['OUTGOING_SITE_ID'])['NUMBER_OF_REFUGEE_CALLS'].sum()
incoming_sms_t = sms_data.groupby(['INCOMING_SITE_ID'])['NUMBER_OF_SMS'].sum()-\
                 sms_data.groupby(['INCOMING_SITE_ID'])['NUMBER_OF_REFUGEE_SMS'].sum()
outgoing_sms_t = sms_data.groupby(['OUTGOING_SITE_ID'])['NUMBER_OF_SMS'].sum()-\
                 sms_data.groupby(['OUTGOING_SITE_ID'])['NUMBER_OF_REFUGEE_SMS'].sum()

incoming_calls_r = cdr_data.groupby(['INCOMING_SITE_ID'])['NUMBER_OF_REFUGEE_CALLS'].sum()
outgoing_calls_r = cdr_data.groupby(['OUTGOING_SITE_ID'])['NUMBER_OF_REFUGEE_CALLS'].sum()
incoming_sms_r = sms_data.groupby(['INCOMING_SITE_ID'])['NUMBER_OF_REFUGEE_SMS'].sum()
outgoing_sms_r = sms_data.groupby(['OUTGOING_SITE_ID'])['NUMBER_OF_REFUGEE_SMS'].sum()

new_df = pd.concat([incoming_calls_t, outgoing_calls_t,incoming_sms_t,outgoing_sms_t,
                    incoming_calls_r, outgoing_calls_r,incoming_sms_r,outgoing_sms_r],
                   axis = 1).fillna(0)
new_df.columns =  ['calls_incoming_t','calls_outgoing_t','sms_incoming_t','sms_outgoing_t',
                     'calls_incoming_r','calls_outgoing_r','sms_incoming_r','sms_outgoing_r']
dict_calls = new_df.to_dict()

for key in dict_calls.keys():
    shapefile[key] = shapefile['BTS_ID'].map(dict_calls[key])
shapefile = shapefile.fillna(0)

### Evaluationg sigma_c for each polygon (SITE) both for turkish and refugee
shapefile['calls_incoming_density_t'] = shapefile['area_fract']*shapefile['calls_incoming_t']/shapefile['area_voron']
shapefile['sms_incoming_density_t'] = shapefile['area_fract']*shapefile['sms_incoming_t']/shapefile['area_voron']
shapefile['calls_outgoing_density_t'] = shapefile['area_fract']*shapefile['calls_outgoing_t']/shapefile['area_voron']
shapefile['sms_outgoing_density_t'] = shapefile['area_fract']*shapefile['sms_outgoing_t']/shapefile['area_voron']

shapefile['calls_incoming_density_r'] = shapefile['area_fract']*shapefile['calls_incoming_r']/shapefile['area_voron']
shapefile['sms_incoming_density_r'] = shapefile['area_fract']*shapefile['sms_incoming_r']/shapefile['area_voron']
shapefile['calls_outgoing_density_r'] = shapefile['area_fract']*shapefile['calls_outgoing_r']/shapefile['area_voron']
shapefile['sms_outgoing_density_r'] = shapefile['area_fract']*shapefile['sms_outgoing_r']/shapefile['area_voron']

df_sigma_c = shapefile.groupby('NAME_1')[['calls_incoming_density_t','sms_incoming_density_t',
                                          'calls_outgoing_density_t','sms_outgoing_density_t',
                                          'calls_incoming_density_r','sms_incoming_density_r',
                                          'calls_outgoing_density_r','sms_outgoing_density_r','area']].sum()
df_sigma_c = df_sigma_c.sort_index()
# ------------------------------------------------------------------------------------------------ #


# ------------------------------------------------------------------------------------------------ #
### Concatenation of population densities and mobile phone activity dentisies
# Export the dataframe containing the densities
res = pd.concat([df_sigma_c, groundtruth],axis = 1)
res['pop_density_r'] = res['Refugees']/res['area']
res['pop_density_t'] = res['Population']/res['area']
res = res.fillna(0)
#res = res[(res.call_density>0) & (res.pop_density>0)]
res.to_pickle(output_densities_name)
# ------------------------------------------------------------------------------------------------ #





# ------------------------------------------------------------------------------------------------ #
def setup_mpl():
    mpl.rc('font', size=10)
    mpl.rcParams['legend.fontsize'] = 'small'
    mpl.rcParams['legend.fontsize'] = 'small'
    mpl.rcParams['xtick.labelsize'] = 'small'
    mpl.rcParams['ytick.labelsize'] = 'small'
    mpl.rcParams['font.family']='Arial'
    mpl.rcParams['xtick.major.pad']='6'
    mpl.rcParams['ytick.major.pad']='6'
    mpl.rcParams['lines.linewidth'] = 1
    mpl.rcParams['xtick.major.width'] = 1
    mpl.rcParams['ytick.major.width'] = 1
    mpl.rcParams['xtick.minor.width'] = 1
    mpl.rcParams['ytick.minor.width'] = 1
    mpl.rcParams['xtick.major.size'] = 3
    mpl.rcParams['ytick.major.size'] = 3
    mpl.rcParams['xtick.minor.size'] = 1.5
    mpl.rcParams['ytick.minor.size'] = 1.5
    mpl.rcParams['axes.linewidth'] = 1
    mpl.rcParams['ytick.direction'] = 'in'
    mpl.rcParams['xtick.direction'] = 'in'
    mpl.rcParams['xtick.top']=True
    mpl.rcParams['ytick.right']=True
    mpl.rcParams['mathtext.default']='regular'


setup_mpl()

fig,ax = plt.subplots(2,2,figsize=(7,7))
axes = list(flatten(ax))
for a,column in zip(axes,['calls_incoming_density_r','calls_outgoing_density_r','sms_incoming_density_r','sms_outgoing_density_r']):
    a.set_title(column.replace('density','').replace('_',' '))
    a.scatter(res[column].values,res.pop_density.values)
    a.set_yscale('log')
    a.set_xscale('log')
    a.set_ylim(min(res.pop_density[res.pop_density>0]*0.5), max(res.pop_density[res.pop_density>0]*2.2))
    a.set_xlim(min(res[column][res[column]>0]*0.5), max(res[column][res[column]>0]*2.2))
    a.set_ylabel(r'population density ($Km^{-2}$)')
    a.set_xlabel(r'cdr density ($Km^{-2}$)')
fig.tight_layout()
# plt.savefig(fig_output,bbox_inches = 'tight')
# ------------------------------------------------------------------------------------------------ #
